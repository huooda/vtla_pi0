import tensorflow_datasets as tfds
import tensorflow as tf
import os

# --- é…ç½® ---
# è¦ä¸‹è½½çš„æ•°æ®é›†å®˜æ–¹åç§°åˆ—è¡¨
# æ³¨æ„ï¼šåœ¨tfdsä¸­ï¼ŒOpen-Xæ•°æ®é›†é€šå¸¸éœ€è¦ 'oxe/' å‰ç¼€
DATASETS_TO_DOWNLOAD = {
    'Berkeley Bridge': 'oxe/bridge_data',
    'Language Table': 'oxe/language_table',
    'Maniskill': 'oxe/maniskill_dataset'
}

# æ‚¨æƒ³ä¸‹è½½çš„æ¯ä¸ªæ•°æ®é›†çš„æ ·æœ¬æ•°é‡
NUM_SAMPLES_PER_DATASET = 1000

# æ•°æ®å°†è¢«ä¸‹è½½åˆ°è¿™ä¸ªç›®å½•ä¸‹ï¼Œä»¥ä¿æŒé¡¹ç›®æ•´æ´
DOWNLOAD_DIR = 'dataset/tfds_data'

# --- è„šæœ¬ ---

def download_and_verify_subset(friendly_name: str, tfds_name: str, num_samples: int, data_dir: str):
    """
    ä¸‹è½½å¹¶éªŒè¯æŒ‡å®šæ•°æ®é›†çš„å­é›†ã€‚
    """
    print(f"\n{'='*50}")
    print(f"å‡†å¤‡ä¸‹è½½æ•°æ®é›†: '{friendly_name}' (TFDS name: '{tfds_name}')")
    print(f"ç›®æ ‡æ ·æœ¬æ•°: {num_samples}")
    print(f"ä¸‹è½½ç›®å½•: {data_dir}")
    print(f"{'='*50}")

    try:
        # å®šä¹‰è¦åŠ è½½çš„æ•°æ®åˆ†å‰²å’Œæ•°é‡ï¼Œä¾‹å¦‚ 'train[:1000]'
        split_selection = f'train[:{num_samples}]'

        # ä½¿ç”¨ tfds.load è¿›è¡Œæµå¼åŠ è½½å’Œä¸‹è½½
        # TFDS ä¼šåœ¨åå°æ™ºèƒ½å¤„ç†ï¼Œåªä¸‹è½½å’Œå‡†å¤‡æ‰€éœ€çš„æœ€å°‘æ–‡ä»¶
        ds = tfds.load(
            tfds_name,
            split=split_selection,
            data_dir=data_dir,
            try_gcs=True,  # å°è¯•ä» Google Cloud Storage ç›´æ¥è®¿é—®
        )

        print(f"\nğŸ‰ æˆåŠŸï¼'{friendly_name}' çš„æ•°æ®åŠ è½½å™¨å·²å‡†å¤‡å°±ç»ªã€‚")
        
        # --- éªŒè¯ä¸‹è½½çš„æ•°æ® ---
        print("æ­£åœ¨éªŒè¯æ•°æ®...")
        episode_count = 0
        for episode in ds.take(1):  # åªå–ä¸€ä¸ªæ ·æœ¬è¿›è¡Œå¿«é€ŸéªŒè¯
            episode_count += 1
            steps = episode['steps']
            first_step = next(iter(steps))
            
            # å°è¯•è·å–è¯­è¨€æŒ‡ä»¤ï¼Œå¦‚æœå­˜åœ¨çš„è¯
            if 'language_instruction' in first_step:
                instruction = first_step['language_instruction'].numpy().decode('utf-8')
                print(f"  - æ ·æœ¬è½¨è¿¹çš„è¯­è¨€æŒ‡ä»¤: '{instruction}'")
            else:
                print("  - æ ·æœ¬è½¨è¿¹æ²¡æœ‰è¯­è¨€æŒ‡ä»¤ã€‚")
            
            num_steps = tf.data.experimental.cardinality(steps)
            print(f"  - æ ·æœ¬è½¨è¿¹çš„é•¿åº¦: {num_steps} æ­¥")

        if episode_count == 0:
            print("  - è­¦å‘Š: éªŒè¯æ—¶æœªèƒ½ä»æ•°æ®åŠ è½½å™¨ä¸­è·å–ä»»ä½•æ ·æœ¬ã€‚")
            
    except Exception as e:
        print(f"\nâŒ ä¸‹è½½æˆ–å¤„ç† '{friendly_name}' æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
        print("  å¯èƒ½çš„åŸå› åŒ…æ‹¬:")
        print("  1. ç½‘ç»œè¿æ¥é—®é¢˜æˆ–æ— æ³•è®¿é—®GCSã€‚")
        print("  2. æ•°æ®é›†åç§°ä¸æ­£ç¡®ã€‚è¯·ç¡®è®¤TFDSä¸­çš„å®˜æ–¹åç§°ã€‚")
        print(f"  3. ç£ç›˜ç©ºé—´ä¸è¶³æˆ– '{data_dir}' ç›®å½•æ²¡æœ‰å†™å…¥æƒé™ã€‚")

def main():
    """
    ä¸»å‡½æ•°ï¼Œç”¨äºæ‰§è¡Œæ•°æ®é›†ä¸‹è½½æµç¨‹ã€‚
    """
    print("--- Open X-Embodiment æ•°æ®é›†å­é›†ä¸‹è½½è„šæœ¬ ---")
    
    # ç¡®ä¿ä¸‹è½½ç›®å½•å­˜åœ¨
    if not os.path.exists(DOWNLOAD_DIR):
        print(f"åˆ›å»ºä¸‹è½½ç›®å½•: {DOWNLOAD_DIR}")
        os.makedirs(DOWNLOAD_DIR)

    # å¾ªç¯ä¸‹è½½æ‰€æœ‰æŒ‡å®šçš„æ•°æ®é›†
    for friendly_name, tfds_name in DATASETS_TO_DOWNLOAD.items():
        download_and_verify_subset(
            friendly_name=friendly_name,
            tfds_name=tfds_name,
            num_samples=NUM_SAMPLES_PER_DATASET,
            data_dir=DOWNLOAD_DIR
        )
    
    print(f"\n{'='*50}")
    print("æ‰€æœ‰æŒ‡å®šçš„ä¸‹è½½ä»»åŠ¡å·²æ‰§è¡Œå®Œæ¯•ã€‚")
    print(f"è¯·æ£€æŸ¥ '{DOWNLOAD_DIR}' ç›®å½•æŸ¥çœ‹ä¸‹è½½çš„æ•°æ®ã€‚")
    print("="*50)


if __name__ == '__main__':
    # ç¦ç”¨ TensorFlow çš„ä¸€äº›å†…å­˜å¢é•¿è¡Œä¸ºï¼Œè¿™å¯¹äºä½¿ç”¨ GPU æ˜¯ä¸€ä¸ªå¥½ä¹ æƒ¯
    gpus = tf.config.list_physical_devices('GPU')
    if gpus:
        try:
            for gpu in gpus:
                tf.config.experimental.set_memory_growth(gpu, True)
        except RuntimeError as e:
            # å¿…é¡»åœ¨ç¨‹åºå¯åŠ¨æ—¶è®¾ç½®å†…å­˜å¢é•¿
            print(e)
            
    main() 